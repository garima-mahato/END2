{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "END2_Session10_END2 Translation using Seq2Seq and Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxCla6HFCtRH",
        "outputId": "042e1e6d-6eda-4c62-f0fa-012651f48607"
      },
      "source": [
        "# %matplotlib inline\n",
        "!pip install bcolz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 28.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 30.9MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 32.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 33.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 34.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 32.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 32.3MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 31.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 31.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 31.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 31.9MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 31.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 31.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 31.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 31.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 31.9MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 31.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 31.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 31.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 327kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 337kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 348kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 358kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 368kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 378kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 389kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 399kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 419kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 430kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 440kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 450kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 460kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 471kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 624kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 645kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 655kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 665kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 675kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 686kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 696kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 706kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 716kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 737kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 747kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 757kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 768kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 778kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 788kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 798kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 808kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 829kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 839kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 849kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 860kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 870kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 880kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 890kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 901kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 921kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 931kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 942kB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 952kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 962kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 972kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 983kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 993kB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 31.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from bcolz) (1.19.5)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp37-cp37m-linux_x86_64.whl size=2650813 sha256=f8eb828704f4fd0de6b270393fb3163df653db4bd260ff9297ace3b43c7b9191\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOr51ZdbymLp",
        "outputId": "75a90588-26a0-4248-e5b3-06e6839b1aeb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Sm1RVyDOVE"
      },
      "source": [
        "\n",
        "NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n",
        "*******************************************************************************\n",
        "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
        "[PyTorch Source](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
        "\n",
        "This is the third and final tutorial on doing \"NLP From Scratch\", where we\n",
        "write our own classes and functions to preprocess the data to do our NLP\n",
        "modeling tasks. We hope after you complete this tutorial that you'll proceed to\n",
        "learn how `torchtext` can handle much of this preprocessing for you in the\n",
        "three tutorials immediately following this one.\n",
        "\n",
        "In this project we will be teaching a neural network to translate from\n",
        "English to French.\n",
        "\n",
        "::\n",
        "\n",
        "    [KEY: > input, = target, < output]\n",
        "\n",
        "    > she is being blackmailed by him .\n",
        "    = il exerce sur elle du chantage .\n",
        "    < elle va beaucoup lui lui . <EOS>\n",
        "\n",
        "    > you re very religious aren t you ?\n",
        "    = vous etes tres religieuses n est ce pas ?\n",
        "    < vous etes tres religieux n est ce pas ? <EOS>\n",
        "\n",
        "    > he is on the team .\n",
        "    = il fait partie de l equipe .\n",
        "    < il est partie de la equipe . <EOS>\n",
        "\n",
        "    > you re the leader .\n",
        "    = c est vous la chef .\n",
        "    < vous etes la chef chef . <EOS>\n",
        "\n",
        "... to varying degrees of success.\n",
        "\n",
        "This is made possible by the simple but powerful idea of the [sequence to sequence network](https://arxiv.org/abs/1409.3215), in which two\n",
        "recurrent neural networks work together to transform one sequence to\n",
        "another. An encoder network condenses an input sequence into a vector,\n",
        "and a decoder network unfolds that vector into a new sequence.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "   :alt:\n",
        "\n",
        "To improve upon this model we'll use an [attention\n",
        "mechanism](https://arxiv.org/abs/1409.0473), which lets the decoder\n",
        "learn to focus over a specific range of the input sequence.\n",
        "\n",
        "**Recommended Reading:**\n",
        "\n",
        "I assume you have at least installed PyTorch, know Python, and\n",
        "understand Tensors:\n",
        "\n",
        "-  https://pytorch.org/ For installation instructions\n",
        "-  [Deep Learning with PyTorch](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html): A 60 Minute Blitz to get started with PyTorch in general\n",
        "-  [Learning PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) for a wide and deep overview\n",
        "\n",
        "\n",
        "It would also be useful to know about Sequence to Sequence networks and\n",
        "how they work:\n",
        "\n",
        "-  [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
        "-  [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
        "-  [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
        "-  [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)\n",
        "\n",
        "\n",
        "\n",
        "![Image](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
        "\n",
        "**Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EEWOCJLDD-E"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import bcolz  # to process the data from Glove File \n",
        "import pickle # to dump and load pretrained glove vectors \n",
        "import copy   # to make deepcopy of python lists and dictionaries\n",
        "import operator\n",
        "import numpy as np\n",
        "from pandas import DataFrame # to visualize the glove word embeddings in form of DataFrame\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30yEbATJDXCF"
      },
      "source": [
        "Loading data files\n",
        "==================\n",
        "\n",
        "The data for this project is a set of many thousands of English to\n",
        "French translation pairs.\n",
        "\n",
        "[This question on Open Data Stack\n",
        "Exchange](https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages)\n",
        "pointed me/him to the open translation site https://tatoeba.org/ which has\n",
        "downloads available at https://tatoeba.org/eng/downloads - and better\n",
        "yet, someone did the extra work of splitting language pairs into\n",
        "individual text files here: https://www.manythings.org/anki/\n",
        "\n",
        "The English to French pairs are too big to include in the repo, so\n",
        "download to ``data/eng-fra.txt`` before continuing. The file is a tab\n",
        "separated list of translation pairs:\n",
        "\n",
        "::\n",
        "\n",
        "    I am cold.    J'ai froid.\n",
        "\n",
        ".. Note::\n",
        "   Download the data from\n",
        "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
        "   and extract it to the current directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_EPl_QFDUSE",
        "outputId": "4624cdd5-74c0-4893-f01d-83f6613c34ff"
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "\n",
        "!unzip data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-18 06:05:16--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.84.216.43, 99.84.216.80, 99.84.216.15, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.84.216.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-07-18 06:05:16 (62.0 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugKjISLqznF-"
      },
      "source": [
        "Download  and Unzip Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVn2PBI6zdRg",
        "outputId": "51de98a7-0622-4299-d2c6-829ceef63024"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
        "\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-17 17:47:40--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2021-07-17 17:47:40--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2021-07-17 17:47:40--  http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.10MB/s    in 2m 40s  \n",
            "\n",
            "2021-07-17 17:50:20 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Opt0fXOfRc"
      },
      "source": [
        "print(len(lines))          # number of words (aka vocabulary size)\n",
        "print(len(lines[0]))       # length of a line\n",
        "print(lines[130][0])       # word 130\n",
        "print(lines[130][1:])      # vector representation of word 130\n",
        "print(len(lines[130][1:])) # dimensionality of word 130\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ4g0l2aRYAr"
      },
      "source": [
        "#### Loading and Saving Glove Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkdS9ZtC1oXB"
      },
      "source": [
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'/gdrive/MyDrive/TSAI_END2/Session10/6B.300.dat', mode='w')\n",
        "\n",
        "with open(f'/content/glove.6B.300d.txt', 'rb') as f:\n",
        "    for l in f:\n",
        "        line = l.decode().split()\n",
        "        word = line[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        idx += 1\n",
        "        vect = np.array(line[1:]).astype(np.float)\n",
        "        vectors.append(vect)\n",
        "    \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400001, 300)), rootdir=f'/gdrive/MyDrive/TSAI_END2/Session10/6B.300.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'/content/drive/MyDrive/TSAI_END2/Session10/glove.6B.300_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'/content/drive/MyDrive/TSAI_END2/Session10/glove.6B.300_idx.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdPjq-hd8UYW"
      },
      "source": [
        "pickle.dump(words, open(f'./glove.6B.300_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'./glove.6B.300_idx.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpeptdfO9tro",
        "outputId": "21418792-b162-47e1-de1d-db515d55057d"
      },
      "source": [
        "!ls '/content/drive/MyDrive/TSAI_END2/Session10'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6B.300.dat  glove.6B.300_idx.pkl    glove.6B.50_idx.pkl\n",
            "6B.50.dat   glove.6B.300_words.pkl  glove.6B.50_words.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTIKUn1lcu2a"
      },
      "source": [
        "#### Load saved vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UilzgUKWRfWZ"
      },
      "source": [
        "vectors = bcolz.open(f'/content/drive/MyDrive/TSAI_END2/Session10/6B.300.dat')[:]\n",
        "words = pickle.load(open(f'/content/drive/MyDrive/TSAI_END2/Session10/glove.6B.300_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'/content/drive/MyDrive/TSAI_END2/Session10/glove.6B.300_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCBGOD0XT2bP"
      },
      "source": [
        "glove_df = DataFrame(vectors, columns=range(1,301), index=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyUmAVY4Uxrt"
      },
      "source": [
        "#### Visualize the Glove Word Embeddings by making a Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "B259PP29T8Ro",
        "outputId": "9b562a98-e75c-4ada-bfba-269e7a9fc0a8"
      },
      "source": [
        "glove_df[200:210]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>300</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>according</th>\n",
              "      <td>-0.279610</td>\n",
              "      <td>0.137320</td>\n",
              "      <td>0.043514</td>\n",
              "      <td>0.333020</td>\n",
              "      <td>-0.168460</td>\n",
              "      <td>0.067218</td>\n",
              "      <td>-0.166420</td>\n",
              "      <td>0.157180</td>\n",
              "      <td>-0.121350</td>\n",
              "      <td>-1.73860</td>\n",
              "      <td>-0.024858</td>\n",
              "      <td>-0.265710</td>\n",
              "      <td>0.175370</td>\n",
              "      <td>0.173250</td>\n",
              "      <td>-0.002423</td>\n",
              "      <td>0.159280</td>\n",
              "      <td>-0.186030</td>\n",
              "      <td>0.251630</td>\n",
              "      <td>-0.386520</td>\n",
              "      <td>-0.336200</td>\n",
              "      <td>0.126930</td>\n",
              "      <td>0.073719</td>\n",
              "      <td>0.249740</td>\n",
              "      <td>0.456310</td>\n",
              "      <td>-0.20157</td>\n",
              "      <td>0.017940</td>\n",
              "      <td>-0.085641</td>\n",
              "      <td>0.082276</td>\n",
              "      <td>0.202490</td>\n",
              "      <td>-0.137970</td>\n",
              "      <td>0.040790</td>\n",
              "      <td>0.547840</td>\n",
              "      <td>-0.041509</td>\n",
              "      <td>0.19313</td>\n",
              "      <td>-0.80545</td>\n",
              "      <td>-0.226530</td>\n",
              "      <td>0.200270</td>\n",
              "      <td>-0.039198</td>\n",
              "      <td>-0.175200</td>\n",
              "      <td>-0.179190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063811</td>\n",
              "      <td>0.47207</td>\n",
              "      <td>0.037923</td>\n",
              "      <td>-0.361250</td>\n",
              "      <td>0.209150</td>\n",
              "      <td>-0.245690</td>\n",
              "      <td>0.258970</td>\n",
              "      <td>-0.060094</td>\n",
              "      <td>-0.137910</td>\n",
              "      <td>-0.233440</td>\n",
              "      <td>-0.192400</td>\n",
              "      <td>-0.188730</td>\n",
              "      <td>0.157660</td>\n",
              "      <td>0.178660</td>\n",
              "      <td>0.11679</td>\n",
              "      <td>-0.192830</td>\n",
              "      <td>-1.9656</td>\n",
              "      <td>-0.10005</td>\n",
              "      <td>0.48721</td>\n",
              "      <td>0.004533</td>\n",
              "      <td>0.010740</td>\n",
              "      <td>-0.108050</td>\n",
              "      <td>0.054460</td>\n",
              "      <td>-0.356230</td>\n",
              "      <td>0.142410</td>\n",
              "      <td>0.184360</td>\n",
              "      <td>-0.032794</td>\n",
              "      <td>-0.066567</td>\n",
              "      <td>-0.16291</td>\n",
              "      <td>0.345220</td>\n",
              "      <td>-0.013469</td>\n",
              "      <td>-0.219000</td>\n",
              "      <td>0.037849</td>\n",
              "      <td>0.155860</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.433770</td>\n",
              "      <td>-0.192290</td>\n",
              "      <td>0.390080</td>\n",
              "      <td>-0.324610</td>\n",
              "      <td>-0.01826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>several</th>\n",
              "      <td>-0.278830</td>\n",
              "      <td>0.298990</td>\n",
              "      <td>-0.092609</td>\n",
              "      <td>-0.149200</td>\n",
              "      <td>0.102150</td>\n",
              "      <td>-0.187240</td>\n",
              "      <td>-0.057946</td>\n",
              "      <td>0.050455</td>\n",
              "      <td>-0.045006</td>\n",
              "      <td>-1.36610</td>\n",
              "      <td>-0.197030</td>\n",
              "      <td>0.145630</td>\n",
              "      <td>-0.187190</td>\n",
              "      <td>0.109940</td>\n",
              "      <td>0.350600</td>\n",
              "      <td>-0.108720</td>\n",
              "      <td>-0.462160</td>\n",
              "      <td>0.170320</td>\n",
              "      <td>0.117040</td>\n",
              "      <td>-0.029810</td>\n",
              "      <td>-0.005754</td>\n",
              "      <td>-0.049542</td>\n",
              "      <td>0.319010</td>\n",
              "      <td>0.118340</td>\n",
              "      <td>-0.32802</td>\n",
              "      <td>-0.151250</td>\n",
              "      <td>-0.486250</td>\n",
              "      <td>0.179170</td>\n",
              "      <td>-0.274930</td>\n",
              "      <td>0.317760</td>\n",
              "      <td>0.235180</td>\n",
              "      <td>0.155060</td>\n",
              "      <td>0.100110</td>\n",
              "      <td>0.23292</td>\n",
              "      <td>-0.55807</td>\n",
              "      <td>-0.352460</td>\n",
              "      <td>0.081194</td>\n",
              "      <td>0.386270</td>\n",
              "      <td>-0.094630</td>\n",
              "      <td>-0.074292</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017501</td>\n",
              "      <td>0.34991</td>\n",
              "      <td>0.358650</td>\n",
              "      <td>-0.209420</td>\n",
              "      <td>0.204730</td>\n",
              "      <td>-0.258020</td>\n",
              "      <td>-0.770900</td>\n",
              "      <td>-0.010413</td>\n",
              "      <td>0.049296</td>\n",
              "      <td>0.006965</td>\n",
              "      <td>0.144020</td>\n",
              "      <td>0.279530</td>\n",
              "      <td>-0.190090</td>\n",
              "      <td>0.130970</td>\n",
              "      <td>0.27707</td>\n",
              "      <td>0.009039</td>\n",
              "      <td>-2.6111</td>\n",
              "      <td>-0.17615</td>\n",
              "      <td>0.25067</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>-0.391450</td>\n",
              "      <td>0.023849</td>\n",
              "      <td>0.234420</td>\n",
              "      <td>0.049562</td>\n",
              "      <td>-0.275360</td>\n",
              "      <td>0.289470</td>\n",
              "      <td>-0.143550</td>\n",
              "      <td>0.219270</td>\n",
              "      <td>0.46774</td>\n",
              "      <td>-0.174360</td>\n",
              "      <td>-0.064541</td>\n",
              "      <td>-0.324480</td>\n",
              "      <td>-0.180430</td>\n",
              "      <td>0.003164</td>\n",
              "      <td>-0.176020</td>\n",
              "      <td>0.478750</td>\n",
              "      <td>-0.237680</td>\n",
              "      <td>-0.224160</td>\n",
              "      <td>-0.366290</td>\n",
              "      <td>-0.21762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>court</th>\n",
              "      <td>0.294920</td>\n",
              "      <td>-0.274790</td>\n",
              "      <td>-0.616680</td>\n",
              "      <td>-0.055869</td>\n",
              "      <td>0.385780</td>\n",
              "      <td>-0.582630</td>\n",
              "      <td>0.730860</td>\n",
              "      <td>-0.119370</td>\n",
              "      <td>-0.041382</td>\n",
              "      <td>-1.42530</td>\n",
              "      <td>-0.305880</td>\n",
              "      <td>-0.056891</td>\n",
              "      <td>-0.195040</td>\n",
              "      <td>0.198430</td>\n",
              "      <td>-0.554840</td>\n",
              "      <td>0.283550</td>\n",
              "      <td>-0.537580</td>\n",
              "      <td>-0.305180</td>\n",
              "      <td>0.569070</td>\n",
              "      <td>-0.239610</td>\n",
              "      <td>0.186620</td>\n",
              "      <td>-0.184960</td>\n",
              "      <td>0.440740</td>\n",
              "      <td>-0.083826</td>\n",
              "      <td>-0.25820</td>\n",
              "      <td>-0.044409</td>\n",
              "      <td>0.139150</td>\n",
              "      <td>-0.541320</td>\n",
              "      <td>-0.460620</td>\n",
              "      <td>0.581210</td>\n",
              "      <td>-0.022778</td>\n",
              "      <td>0.173250</td>\n",
              "      <td>0.178510</td>\n",
              "      <td>0.29736</td>\n",
              "      <td>-0.82185</td>\n",
              "      <td>-0.389630</td>\n",
              "      <td>0.094130</td>\n",
              "      <td>-0.205660</td>\n",
              "      <td>-0.772460</td>\n",
              "      <td>0.181290</td>\n",
              "      <td>...</td>\n",
              "      <td>0.189250</td>\n",
              "      <td>-0.16735</td>\n",
              "      <td>0.412260</td>\n",
              "      <td>0.142210</td>\n",
              "      <td>0.170160</td>\n",
              "      <td>-0.354630</td>\n",
              "      <td>0.061339</td>\n",
              "      <td>0.343660</td>\n",
              "      <td>-0.046048</td>\n",
              "      <td>-1.083400</td>\n",
              "      <td>0.439800</td>\n",
              "      <td>-0.694310</td>\n",
              "      <td>0.207420</td>\n",
              "      <td>0.119580</td>\n",
              "      <td>0.19484</td>\n",
              "      <td>-0.004723</td>\n",
              "      <td>-2.1147</td>\n",
              "      <td>0.18858</td>\n",
              "      <td>1.13600</td>\n",
              "      <td>0.931650</td>\n",
              "      <td>0.113970</td>\n",
              "      <td>0.024541</td>\n",
              "      <td>0.015915</td>\n",
              "      <td>0.209480</td>\n",
              "      <td>-0.301930</td>\n",
              "      <td>-0.062889</td>\n",
              "      <td>0.281870</td>\n",
              "      <td>0.570090</td>\n",
              "      <td>-0.53056</td>\n",
              "      <td>0.285680</td>\n",
              "      <td>0.437920</td>\n",
              "      <td>-0.014297</td>\n",
              "      <td>0.241620</td>\n",
              "      <td>0.506370</td>\n",
              "      <td>0.290290</td>\n",
              "      <td>0.025725</td>\n",
              "      <td>0.136190</td>\n",
              "      <td>-0.207100</td>\n",
              "      <td>0.015589</td>\n",
              "      <td>0.17391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>say</th>\n",
              "      <td>0.056090</td>\n",
              "      <td>0.200350</td>\n",
              "      <td>-0.136570</td>\n",
              "      <td>0.057160</td>\n",
              "      <td>-0.127080</td>\n",
              "      <td>-0.201790</td>\n",
              "      <td>0.284300</td>\n",
              "      <td>0.261590</td>\n",
              "      <td>-0.052328</td>\n",
              "      <td>-1.75730</td>\n",
              "      <td>0.076761</td>\n",
              "      <td>-0.088249</td>\n",
              "      <td>-0.053148</td>\n",
              "      <td>0.581910</td>\n",
              "      <td>0.458550</td>\n",
              "      <td>0.270420</td>\n",
              "      <td>0.020048</td>\n",
              "      <td>0.052781</td>\n",
              "      <td>0.235690</td>\n",
              "      <td>0.287740</td>\n",
              "      <td>0.162650</td>\n",
              "      <td>0.162660</td>\n",
              "      <td>0.349910</td>\n",
              "      <td>-0.291750</td>\n",
              "      <td>-0.67895</td>\n",
              "      <td>0.058927</td>\n",
              "      <td>0.219020</td>\n",
              "      <td>-0.378070</td>\n",
              "      <td>-0.041854</td>\n",
              "      <td>-0.118250</td>\n",
              "      <td>0.445800</td>\n",
              "      <td>0.572670</td>\n",
              "      <td>-0.604510</td>\n",
              "      <td>-0.14544</td>\n",
              "      <td>-0.63381</td>\n",
              "      <td>0.081092</td>\n",
              "      <td>-0.002696</td>\n",
              "      <td>-0.210160</td>\n",
              "      <td>0.180770</td>\n",
              "      <td>-0.514370</td>\n",
              "      <td>...</td>\n",
              "      <td>0.145000</td>\n",
              "      <td>-0.19456</td>\n",
              "      <td>-0.159280</td>\n",
              "      <td>0.204040</td>\n",
              "      <td>-0.080843</td>\n",
              "      <td>0.223510</td>\n",
              "      <td>-0.135650</td>\n",
              "      <td>-0.096678</td>\n",
              "      <td>-0.085022</td>\n",
              "      <td>0.077191</td>\n",
              "      <td>0.182990</td>\n",
              "      <td>0.298280</td>\n",
              "      <td>0.107660</td>\n",
              "      <td>0.042735</td>\n",
              "      <td>0.36590</td>\n",
              "      <td>0.197160</td>\n",
              "      <td>-2.4170</td>\n",
              "      <td>0.10348</td>\n",
              "      <td>0.37408</td>\n",
              "      <td>-0.036688</td>\n",
              "      <td>0.004247</td>\n",
              "      <td>0.044540</td>\n",
              "      <td>-0.124100</td>\n",
              "      <td>0.285000</td>\n",
              "      <td>0.063308</td>\n",
              "      <td>0.182960</td>\n",
              "      <td>0.269000</td>\n",
              "      <td>-0.223500</td>\n",
              "      <td>-0.17115</td>\n",
              "      <td>0.082492</td>\n",
              "      <td>0.189930</td>\n",
              "      <td>-0.544910</td>\n",
              "      <td>0.171560</td>\n",
              "      <td>-0.017652</td>\n",
              "      <td>0.174040</td>\n",
              "      <td>-0.603500</td>\n",
              "      <td>-0.107820</td>\n",
              "      <td>-0.501320</td>\n",
              "      <td>-0.021014</td>\n",
              "      <td>0.44665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>around</th>\n",
              "      <td>-0.469570</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>-0.030859</td>\n",
              "      <td>-0.107720</td>\n",
              "      <td>-0.025968</td>\n",
              "      <td>0.408180</td>\n",
              "      <td>0.218770</td>\n",
              "      <td>0.382240</td>\n",
              "      <td>0.105420</td>\n",
              "      <td>-1.64180</td>\n",
              "      <td>-0.113610</td>\n",
              "      <td>0.291120</td>\n",
              "      <td>0.057045</td>\n",
              "      <td>0.199720</td>\n",
              "      <td>0.291610</td>\n",
              "      <td>0.366450</td>\n",
              "      <td>-0.456570</td>\n",
              "      <td>0.454240</td>\n",
              "      <td>-0.093902</td>\n",
              "      <td>0.331720</td>\n",
              "      <td>0.299060</td>\n",
              "      <td>0.338220</td>\n",
              "      <td>0.281110</td>\n",
              "      <td>-0.142310</td>\n",
              "      <td>0.18127</td>\n",
              "      <td>-0.004856</td>\n",
              "      <td>-0.112540</td>\n",
              "      <td>-0.024092</td>\n",
              "      <td>-0.254640</td>\n",
              "      <td>0.506790</td>\n",
              "      <td>0.098070</td>\n",
              "      <td>0.163230</td>\n",
              "      <td>-0.481590</td>\n",
              "      <td>0.55863</td>\n",
              "      <td>-0.67272</td>\n",
              "      <td>-0.025186</td>\n",
              "      <td>0.163960</td>\n",
              "      <td>0.465680</td>\n",
              "      <td>-0.088058</td>\n",
              "      <td>-0.114930</td>\n",
              "      <td>...</td>\n",
              "      <td>0.850180</td>\n",
              "      <td>0.27484</td>\n",
              "      <td>0.119640</td>\n",
              "      <td>-0.116100</td>\n",
              "      <td>0.069383</td>\n",
              "      <td>-0.413810</td>\n",
              "      <td>-0.262600</td>\n",
              "      <td>-0.124260</td>\n",
              "      <td>0.209350</td>\n",
              "      <td>-0.061349</td>\n",
              "      <td>-0.152320</td>\n",
              "      <td>0.141830</td>\n",
              "      <td>0.320900</td>\n",
              "      <td>0.116200</td>\n",
              "      <td>0.21903</td>\n",
              "      <td>-0.179330</td>\n",
              "      <td>-2.1543</td>\n",
              "      <td>-0.41776</td>\n",
              "      <td>0.08200</td>\n",
              "      <td>0.206420</td>\n",
              "      <td>-0.344030</td>\n",
              "      <td>-0.122760</td>\n",
              "      <td>-0.075667</td>\n",
              "      <td>-0.065374</td>\n",
              "      <td>-0.269220</td>\n",
              "      <td>0.390050</td>\n",
              "      <td>0.199480</td>\n",
              "      <td>-0.015338</td>\n",
              "      <td>-0.22481</td>\n",
              "      <td>-0.043952</td>\n",
              "      <td>0.573730</td>\n",
              "      <td>-0.227680</td>\n",
              "      <td>-0.388810</td>\n",
              "      <td>0.240210</td>\n",
              "      <td>-0.081779</td>\n",
              "      <td>0.140490</td>\n",
              "      <td>0.036649</td>\n",
              "      <td>0.184050</td>\n",
              "      <td>-0.110230</td>\n",
              "      <td>-0.31083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>foreign</th>\n",
              "      <td>-0.095487</td>\n",
              "      <td>-0.209960</td>\n",
              "      <td>-0.199050</td>\n",
              "      <td>0.417170</td>\n",
              "      <td>-0.034925</td>\n",
              "      <td>-0.194490</td>\n",
              "      <td>-0.381970</td>\n",
              "      <td>0.391020</td>\n",
              "      <td>-0.281870</td>\n",
              "      <td>-2.79180</td>\n",
              "      <td>0.354780</td>\n",
              "      <td>0.162590</td>\n",
              "      <td>-0.333660</td>\n",
              "      <td>0.025810</td>\n",
              "      <td>-0.335900</td>\n",
              "      <td>-0.808810</td>\n",
              "      <td>0.071127</td>\n",
              "      <td>0.015254</td>\n",
              "      <td>-0.131030</td>\n",
              "      <td>-0.122410</td>\n",
              "      <td>-0.198780</td>\n",
              "      <td>0.070378</td>\n",
              "      <td>0.983250</td>\n",
              "      <td>-0.055934</td>\n",
              "      <td>-0.30992</td>\n",
              "      <td>0.323390</td>\n",
              "      <td>0.192530</td>\n",
              "      <td>0.245240</td>\n",
              "      <td>-0.130560</td>\n",
              "      <td>0.260320</td>\n",
              "      <td>-0.476990</td>\n",
              "      <td>-0.203560</td>\n",
              "      <td>0.213620</td>\n",
              "      <td>0.04692</td>\n",
              "      <td>-0.89056</td>\n",
              "      <td>-0.688440</td>\n",
              "      <td>0.192790</td>\n",
              "      <td>-0.446870</td>\n",
              "      <td>0.116330</td>\n",
              "      <td>0.271760</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.226100</td>\n",
              "      <td>-0.40134</td>\n",
              "      <td>0.082960</td>\n",
              "      <td>0.521950</td>\n",
              "      <td>0.833800</td>\n",
              "      <td>-0.722610</td>\n",
              "      <td>-0.072281</td>\n",
              "      <td>-0.001010</td>\n",
              "      <td>-0.394940</td>\n",
              "      <td>0.068606</td>\n",
              "      <td>-0.099127</td>\n",
              "      <td>0.304630</td>\n",
              "      <td>-0.454250</td>\n",
              "      <td>-0.055678</td>\n",
              "      <td>-0.37260</td>\n",
              "      <td>0.151170</td>\n",
              "      <td>-1.6924</td>\n",
              "      <td>-0.41482</td>\n",
              "      <td>0.40577</td>\n",
              "      <td>-0.217920</td>\n",
              "      <td>0.402590</td>\n",
              "      <td>-0.233630</td>\n",
              "      <td>0.250910</td>\n",
              "      <td>-0.123690</td>\n",
              "      <td>0.548910</td>\n",
              "      <td>-0.432750</td>\n",
              "      <td>-0.079733</td>\n",
              "      <td>0.305510</td>\n",
              "      <td>0.32427</td>\n",
              "      <td>0.134810</td>\n",
              "      <td>-0.037153</td>\n",
              "      <td>-0.541010</td>\n",
              "      <td>0.109550</td>\n",
              "      <td>-0.251420</td>\n",
              "      <td>0.260630</td>\n",
              "      <td>0.715130</td>\n",
              "      <td>-0.140730</td>\n",
              "      <td>0.043425</td>\n",
              "      <td>-0.902620</td>\n",
              "      <td>0.49778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.441890</td>\n",
              "      <td>0.242480</td>\n",
              "      <td>-0.229970</td>\n",
              "      <td>0.172260</td>\n",
              "      <td>-0.096344</td>\n",
              "      <td>0.136520</td>\n",
              "      <td>0.039942</td>\n",
              "      <td>0.120760</td>\n",
              "      <td>0.389680</td>\n",
              "      <td>-0.96754</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.275010</td>\n",
              "      <td>-0.175220</td>\n",
              "      <td>0.428170</td>\n",
              "      <td>0.012163</td>\n",
              "      <td>-0.045286</td>\n",
              "      <td>-0.129230</td>\n",
              "      <td>-0.029375</td>\n",
              "      <td>0.102550</td>\n",
              "      <td>-0.350450</td>\n",
              "      <td>-0.212720</td>\n",
              "      <td>-0.130870</td>\n",
              "      <td>-0.012698</td>\n",
              "      <td>0.092539</td>\n",
              "      <td>-0.06211</td>\n",
              "      <td>0.190630</td>\n",
              "      <td>-0.344460</td>\n",
              "      <td>-0.141980</td>\n",
              "      <td>0.009539</td>\n",
              "      <td>-0.286660</td>\n",
              "      <td>-0.187720</td>\n",
              "      <td>0.611720</td>\n",
              "      <td>0.137120</td>\n",
              "      <td>0.17352</td>\n",
              "      <td>-1.03470</td>\n",
              "      <td>-0.230870</td>\n",
              "      <td>0.407430</td>\n",
              "      <td>0.433120</td>\n",
              "      <td>-0.360320</td>\n",
              "      <td>0.036961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279180</td>\n",
              "      <td>0.04196</td>\n",
              "      <td>0.064526</td>\n",
              "      <td>-0.200040</td>\n",
              "      <td>0.295430</td>\n",
              "      <td>-0.187930</td>\n",
              "      <td>0.192390</td>\n",
              "      <td>-0.072376</td>\n",
              "      <td>0.274850</td>\n",
              "      <td>0.285530</td>\n",
              "      <td>-0.097114</td>\n",
              "      <td>0.004545</td>\n",
              "      <td>0.148490</td>\n",
              "      <td>0.090044</td>\n",
              "      <td>0.13226</td>\n",
              "      <td>0.028023</td>\n",
              "      <td>-1.9839</td>\n",
              "      <td>-0.42138</td>\n",
              "      <td>-0.21883</td>\n",
              "      <td>0.160240</td>\n",
              "      <td>0.032295</td>\n",
              "      <td>-0.058029</td>\n",
              "      <td>0.103180</td>\n",
              "      <td>0.123430</td>\n",
              "      <td>-0.168160</td>\n",
              "      <td>0.682780</td>\n",
              "      <td>-0.516350</td>\n",
              "      <td>-0.147090</td>\n",
              "      <td>0.12471</td>\n",
              "      <td>0.165170</td>\n",
              "      <td>0.070977</td>\n",
              "      <td>-0.389240</td>\n",
              "      <td>-0.269190</td>\n",
              "      <td>-0.342620</td>\n",
              "      <td>0.324960</td>\n",
              "      <td>0.279240</td>\n",
              "      <td>-0.266480</td>\n",
              "      <td>-0.776380</td>\n",
              "      <td>-0.054478</td>\n",
              "      <td>-0.13019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>until</th>\n",
              "      <td>0.045036</td>\n",
              "      <td>-0.162020</td>\n",
              "      <td>0.401750</td>\n",
              "      <td>-0.032719</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>-0.201640</td>\n",
              "      <td>0.112720</td>\n",
              "      <td>-0.183880</td>\n",
              "      <td>0.233380</td>\n",
              "      <td>-1.86600</td>\n",
              "      <td>-0.240630</td>\n",
              "      <td>-0.107330</td>\n",
              "      <td>0.321970</td>\n",
              "      <td>-0.139860</td>\n",
              "      <td>-0.089932</td>\n",
              "      <td>0.090911</td>\n",
              "      <td>0.179980</td>\n",
              "      <td>-0.082335</td>\n",
              "      <td>0.108850</td>\n",
              "      <td>0.146420</td>\n",
              "      <td>0.186290</td>\n",
              "      <td>0.090300</td>\n",
              "      <td>0.239850</td>\n",
              "      <td>-0.092648</td>\n",
              "      <td>-0.22982</td>\n",
              "      <td>-0.096040</td>\n",
              "      <td>-0.224780</td>\n",
              "      <td>-0.145510</td>\n",
              "      <td>-0.636020</td>\n",
              "      <td>0.010182</td>\n",
              "      <td>0.195490</td>\n",
              "      <td>0.153900</td>\n",
              "      <td>0.271010</td>\n",
              "      <td>0.30660</td>\n",
              "      <td>-0.77808</td>\n",
              "      <td>-0.012936</td>\n",
              "      <td>-0.094754</td>\n",
              "      <td>0.559800</td>\n",
              "      <td>-0.091743</td>\n",
              "      <td>0.416900</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.34940</td>\n",
              "      <td>-0.176270</td>\n",
              "      <td>-0.164460</td>\n",
              "      <td>-0.250770</td>\n",
              "      <td>-0.295420</td>\n",
              "      <td>0.013784</td>\n",
              "      <td>-0.373670</td>\n",
              "      <td>0.083342</td>\n",
              "      <td>-0.074837</td>\n",
              "      <td>-0.108870</td>\n",
              "      <td>0.145720</td>\n",
              "      <td>-0.053223</td>\n",
              "      <td>0.225040</td>\n",
              "      <td>0.49595</td>\n",
              "      <td>0.014406</td>\n",
              "      <td>-2.0235</td>\n",
              "      <td>-0.39581</td>\n",
              "      <td>0.16585</td>\n",
              "      <td>0.170420</td>\n",
              "      <td>-0.327020</td>\n",
              "      <td>-0.268010</td>\n",
              "      <td>-0.005349</td>\n",
              "      <td>0.118980</td>\n",
              "      <td>0.195720</td>\n",
              "      <td>0.491120</td>\n",
              "      <td>0.041823</td>\n",
              "      <td>0.249410</td>\n",
              "      <td>-0.36564</td>\n",
              "      <td>-0.020910</td>\n",
              "      <td>-0.197260</td>\n",
              "      <td>-0.091085</td>\n",
              "      <td>0.112990</td>\n",
              "      <td>-0.275180</td>\n",
              "      <td>-0.317930</td>\n",
              "      <td>0.384110</td>\n",
              "      <td>-0.136790</td>\n",
              "      <td>-0.506100</td>\n",
              "      <td>0.070201</td>\n",
              "      <td>0.31148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>set</th>\n",
              "      <td>-0.330680</td>\n",
              "      <td>0.174590</td>\n",
              "      <td>-0.325450</td>\n",
              "      <td>0.379000</td>\n",
              "      <td>0.125360</td>\n",
              "      <td>-0.074719</td>\n",
              "      <td>-0.046026</td>\n",
              "      <td>-0.058392</td>\n",
              "      <td>-0.045669</td>\n",
              "      <td>-1.33110</td>\n",
              "      <td>0.409900</td>\n",
              "      <td>0.419970</td>\n",
              "      <td>0.073290</td>\n",
              "      <td>-0.034584</td>\n",
              "      <td>-0.325820</td>\n",
              "      <td>0.022083</td>\n",
              "      <td>0.067834</td>\n",
              "      <td>-0.207580</td>\n",
              "      <td>-0.048283</td>\n",
              "      <td>0.091015</td>\n",
              "      <td>0.089587</td>\n",
              "      <td>-0.046688</td>\n",
              "      <td>0.185640</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.24787</td>\n",
              "      <td>0.058006</td>\n",
              "      <td>-0.097955</td>\n",
              "      <td>-0.160070</td>\n",
              "      <td>-0.260060</td>\n",
              "      <td>0.204210</td>\n",
              "      <td>0.096925</td>\n",
              "      <td>0.307040</td>\n",
              "      <td>-0.025169</td>\n",
              "      <td>0.62919</td>\n",
              "      <td>-0.98415</td>\n",
              "      <td>0.038619</td>\n",
              "      <td>-0.375850</td>\n",
              "      <td>0.301880</td>\n",
              "      <td>-0.263370</td>\n",
              "      <td>0.428480</td>\n",
              "      <td>...</td>\n",
              "      <td>0.228250</td>\n",
              "      <td>-0.27699</td>\n",
              "      <td>0.250080</td>\n",
              "      <td>0.067117</td>\n",
              "      <td>-0.027048</td>\n",
              "      <td>-0.011291</td>\n",
              "      <td>-0.335750</td>\n",
              "      <td>0.060869</td>\n",
              "      <td>0.519090</td>\n",
              "      <td>-0.048897</td>\n",
              "      <td>-0.067377</td>\n",
              "      <td>-0.064250</td>\n",
              "      <td>0.609530</td>\n",
              "      <td>0.639080</td>\n",
              "      <td>-0.14792</td>\n",
              "      <td>0.170250</td>\n",
              "      <td>-2.1690</td>\n",
              "      <td>0.17169</td>\n",
              "      <td>0.41858</td>\n",
              "      <td>-0.148040</td>\n",
              "      <td>0.350980</td>\n",
              "      <td>-0.218970</td>\n",
              "      <td>-0.295720</td>\n",
              "      <td>-0.060498</td>\n",
              "      <td>-0.574690</td>\n",
              "      <td>0.275300</td>\n",
              "      <td>-0.441010</td>\n",
              "      <td>0.023605</td>\n",
              "      <td>-0.14858</td>\n",
              "      <td>0.029384</td>\n",
              "      <td>-0.089098</td>\n",
              "      <td>-0.192170</td>\n",
              "      <td>-0.269420</td>\n",
              "      <td>0.147910</td>\n",
              "      <td>0.145190</td>\n",
              "      <td>0.973710</td>\n",
              "      <td>-0.121230</td>\n",
              "      <td>-0.400650</td>\n",
              "      <td>0.052764</td>\n",
              "      <td>0.54662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>political</th>\n",
              "      <td>0.561610</td>\n",
              "      <td>-0.114750</td>\n",
              "      <td>0.421820</td>\n",
              "      <td>-0.146580</td>\n",
              "      <td>0.559030</td>\n",
              "      <td>-0.055492</td>\n",
              "      <td>-0.047198</td>\n",
              "      <td>-0.180620</td>\n",
              "      <td>0.451410</td>\n",
              "      <td>-2.19460</td>\n",
              "      <td>-0.071853</td>\n",
              "      <td>0.122400</td>\n",
              "      <td>0.246660</td>\n",
              "      <td>-0.122470</td>\n",
              "      <td>0.248140</td>\n",
              "      <td>-0.153350</td>\n",
              "      <td>0.152790</td>\n",
              "      <td>0.929340</td>\n",
              "      <td>0.057485</td>\n",
              "      <td>0.161260</td>\n",
              "      <td>0.230990</td>\n",
              "      <td>0.238820</td>\n",
              "      <td>0.450830</td>\n",
              "      <td>0.219870</td>\n",
              "      <td>-0.58242</td>\n",
              "      <td>0.254090</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>0.317270</td>\n",
              "      <td>0.017905</td>\n",
              "      <td>-0.093428</td>\n",
              "      <td>-0.191410</td>\n",
              "      <td>-0.020396</td>\n",
              "      <td>-0.486050</td>\n",
              "      <td>0.27129</td>\n",
              "      <td>-0.61117</td>\n",
              "      <td>0.149090</td>\n",
              "      <td>0.121830</td>\n",
              "      <td>0.669370</td>\n",
              "      <td>-0.018887</td>\n",
              "      <td>-0.091606</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.083122</td>\n",
              "      <td>-0.22120</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.199290</td>\n",
              "      <td>0.415630</td>\n",
              "      <td>-0.168280</td>\n",
              "      <td>-0.054537</td>\n",
              "      <td>0.437520</td>\n",
              "      <td>0.005782</td>\n",
              "      <td>0.057408</td>\n",
              "      <td>-0.303010</td>\n",
              "      <td>0.271360</td>\n",
              "      <td>0.303070</td>\n",
              "      <td>-0.041741</td>\n",
              "      <td>0.56293</td>\n",
              "      <td>0.062314</td>\n",
              "      <td>-1.6413</td>\n",
              "      <td>-0.23018</td>\n",
              "      <td>1.74480</td>\n",
              "      <td>-0.205090</td>\n",
              "      <td>0.225210</td>\n",
              "      <td>-0.180140</td>\n",
              "      <td>-0.129580</td>\n",
              "      <td>-0.431660</td>\n",
              "      <td>0.650840</td>\n",
              "      <td>-0.172870</td>\n",
              "      <td>0.097956</td>\n",
              "      <td>0.395640</td>\n",
              "      <td>0.52575</td>\n",
              "      <td>0.394430</td>\n",
              "      <td>-0.444890</td>\n",
              "      <td>0.103510</td>\n",
              "      <td>0.228380</td>\n",
              "      <td>0.196760</td>\n",
              "      <td>0.163680</td>\n",
              "      <td>0.733660</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>-0.008545</td>\n",
              "      <td>-0.938440</td>\n",
              "      <td>0.60734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                1         2         3    ...       298       299      300\n",
              "according -0.279610  0.137320  0.043514  ...  0.390080 -0.324610 -0.01826\n",
              "several   -0.278830  0.298990 -0.092609  ... -0.224160 -0.366290 -0.21762\n",
              "court      0.294920 -0.274790 -0.616680  ... -0.207100  0.015589  0.17391\n",
              "say        0.056090  0.200350 -0.136570  ... -0.501320 -0.021014  0.44665\n",
              "around    -0.469570  0.000895 -0.030859  ...  0.184050 -0.110230 -0.31083\n",
              "foreign   -0.095487 -0.209960 -0.199050  ...  0.043425 -0.902620  0.49778\n",
              "10        -0.441890  0.242480 -0.229970  ... -0.776380 -0.054478 -0.13019\n",
              "until      0.045036 -0.162020  0.401750  ... -0.506100  0.070201  0.31148\n",
              "set       -0.330680  0.174590 -0.325450  ... -0.400650  0.052764  0.54662\n",
              "political  0.561610 -0.114750  0.421820  ... -0.008545 -0.938440  0.60734\n",
              "\n",
              "[10 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htf4Jj_GVGMn"
      },
      "source": [
        "#### For later processing¶\n",
        "- 'sos' token to be at index = 0\n",
        "- 'eos' token to be at index = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCwWH7wUVja1"
      },
      "source": [
        "sos_index = word2idx['sos']\n",
        "eos_index = word2idx['eos']\n",
        "sos_swap_word = words[0]\n",
        "eos_swap_word = words[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeX20qB3V5Mu"
      },
      "source": [
        "#### Swapping 'sos' token index and 'eos' token index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwRGHmfXV7Hz"
      },
      "source": [
        "words[0], words[sos_index] = words[sos_index], words[0]\n",
        "words[1], words[eos_index] = words[eos_index], words[1]\n",
        "word2idx[sos_swap_word], word2idx['sos'] = word2idx['sos'], word2idx[sos_swap_word]\n",
        "word2idx[eos_swap_word], word2idx['eos'] = word2idx['eos'], word2idx[eos_swap_word]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ImKSH4WvOj"
      },
      "source": [
        "#### Creating Sorted Instance of word2idx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIPWum1oWgVk"
      },
      "source": [
        "word2idx = { k : v for k , v in sorted(word2idx.items(), key=operator.itemgetter(1))}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAY3toaqDxXA"
      },
      "source": [
        "Similar to the character encoding used in the character-level RNN\n",
        "tutorials, we will be representing each word in a language as a one-hot\n",
        "vector, or giant vector of zeros except for a single one (at the index\n",
        "of the word). Compared to the dozens of characters that might exist in a\n",
        "language, there are many many more words, so the encoding vector is much\n",
        "larger. We will however cheat a bit and trim the data to only use a few\n",
        "thousand words per language.\n",
        "\n",
        "![image](https://pytorch.org/tutorials/_images/word-encoding.png)\n",
        "\n",
        "We'll need a unique index per word to use as the inputs and targets of\n",
        "the networks later. To keep track of all this we will use a helper class\n",
        "called ``Lang`` which has word → index (``word2index``) and index → word\n",
        "(``index2word``) dictionaries, as well as a count of each word\n",
        "``word2count`` which will be used to replace rare words later.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b71WvS0-X7Xu"
      },
      "source": [
        "#### Creating 2 Seperate Classes for Input Lang and Ouput Lang\n",
        "\n",
        "Class 1 - > InputLang - built from Glove\n",
        "\n",
        "Class 2 - > OutputLang - built from Target Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-xmITKdYD90"
      },
      "source": [
        "class InputLang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = { k : v for k , v in sorted(word2idx.items(), key=operator.itemgetter(1))}\n",
        "        self.word2count = { word : 1 for word in words }\n",
        "        self.index2word = { i : word for word, i in word2idx.items() }\n",
        "        self.n_words = 400001\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ngtfyUqa-tm"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class OutputLang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"sos\", 1: \"eos\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdDKLAODduG"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFrQoWJbEOYd"
      },
      "source": [
        "The files are all in Unicode, to simplify we will turn Unicode\n",
        "characters to ASCII, make everything lowercase, and trim most\n",
        "punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696X0f6eEMa9"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVorNRFCETgM"
      },
      "source": [
        "To read the data file we will split the file into lines, and then split\n",
        "lines into pairs. The files are all English → Other Language, so if we\n",
        "want to translate from Other Language → English I added the ``reverse``\n",
        "flag to reverse the pairs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD5V5PPHERbk"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = InputLang(lang2)\n",
        "        output_lang = OutputLang(lang1)\n",
        "    else:\n",
        "        input_lang = InputLang(lang1)\n",
        "        output_lang = OutputLang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjaZPWj-Ed1p"
      },
      "source": [
        "Since there are a *lot* of example sentences and we want to train\n",
        "something quickly, we'll trim the data set to only relatively short and\n",
        "simple sentences. Here the maximum length is 10 words (that includes\n",
        "ending punctuation) and we're filtering to sentences that translate to\n",
        "the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
        "earlier).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpLh4takEcl9"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[0].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQpC4FE3EsXQ"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "-  Read text file and split into lines, split lines into pairs\n",
        "-  Normalize text, filter by length and content\n",
        "-  Make word lists from sentences in pairs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQl0eg8BH9BS",
        "outputId": "f7838b27-b6a3-45ea-f0cf-4d0f18ac83ef"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 400005\n",
            "fra 4345\n",
            "['i m slightly hungry .', 'j ai legerement faim .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Zbiow8b0rZ"
      },
      "source": [
        "#### Initializing weight Matrix\n",
        "\n",
        "We must build a matrix of weights that will be loaded into the PyTorch embedding layer. Its shape will be equal to:\n",
        "\n",
        "**(dataset’s vocabulary length, word vectors dimension)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC6WzLQScAG5"
      },
      "source": [
        "matrix_len = input_lang.n_words\n",
        "glove_dim = 300\n",
        "\n",
        "weights_matrix = np.zeros((matrix_len, glove_dim))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(input_lang.word2index):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(glove_dim, ))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IszO9MwEhLRe",
        "outputId": "f3a9e2c4-9c87-49df-dcf2-8c6dc7076662"
      },
      "source": [
        "weights_matrix.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400005, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sklKeEAZEw9A"
      },
      "source": [
        "The Seq2Seq Model\n",
        "=================\n",
        "\n",
        "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
        "sequence and uses its own output as input for subsequent steps.\n",
        "\n",
        "A [Sequence to Sequence network](https://arxiv.org/abs/1409.3215), or\n",
        "seq2seq network, or [Encoder Decoder\n",
        "network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model\n",
        "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
        "an input sequence and outputs a single vector, and the decoder reads\n",
        "that vector to produce an output sequence.\n",
        "\n",
        "![image](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
        "\n",
        "Unlike sequence prediction with a single RNN, where every input\n",
        "corresponds to an output, the seq2seq model frees us from sequence\n",
        "length and order, which makes it ideal for translation between two\n",
        "languages.\n",
        "\n",
        "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
        "black cat\". Most of the words in the input sentence have a direct\n",
        "translation in the output sentence, but are in slightly different\n",
        "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
        "construction there is also one more word in the input sentence. It would\n",
        "be difficult to produce a correct translation directly from the sequence\n",
        "of input words.\n",
        "\n",
        "With a seq2seq model the encoder creates a single vector which, in the\n",
        "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
        "vector — a single point in some N dimensional space of sentences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJZ7qgeoGH25"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "The encoder of a seq2seq network is a RNN that outputs some value for\n",
        "every word from the input sentence. For every input word the encoder\n",
        "outputs a vector and a hidden state, and uses the hidden state for the\n",
        "next input word.\n",
        "\n",
        "![image](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtVkjGRfe-Pb"
      },
      "source": [
        "# def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "#     num_embeddings, embedding_dim = weights_matrix.size()\n",
        "#     emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "#     emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "#     if non_trainable:\n",
        "#         emb_layer.weight.requires_grad = False\n",
        "\n",
        "#     return emb_layer, num_embeddings, embedding_dim"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUFStkIuEqo7"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, weights_matrix=None):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        if weights_matrix is None:\n",
        "          self.embedding.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WzcqRwLGR_c"
      },
      "source": [
        "#Simple Decoder\n",
        "\n",
        "In the simplest seq2seq decoder we use only last output of the encoder.\n",
        "This last output is sometimes called the *context vector* as it encodes\n",
        "context from the entire sequence. This context vector is used as the\n",
        "initial hidden state of the decoder.\n",
        "\n",
        "At every step of decoding, the decoder is given an input token and\n",
        "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
        "token, and the first hidden state is the context vector (the encoder's\n",
        "last hidden state).\n",
        "\n",
        "![image](https://pytorch.org/tutorials/_images/decoder-network.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTpja5ExGQR_"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGMxRg_-Ga5T"
      },
      "source": [
        "# Attention Decoder\n",
        "\n",
        "If only the context vector is passed between the encoder and decoder,\n",
        "that single vector carries the burden of encoding the entire sentence.\n",
        "\n",
        "Attention allows the decoder network to \"focus\" on a different part of\n",
        "the encoder's outputs for every step of the decoder's own outputs. First\n",
        "we calculate a set of *attention weights*. These will be multiplied by\n",
        "the encoder output vectors to create a weighted combination. The result\n",
        "(called ``attn_applied`` in the code) should contain information about\n",
        "that specific part of the input sequence, and thus help the decoder\n",
        "choose the right output words.\n",
        "\n",
        "![image](https://i.imgur.com/1152PYf.png)\n",
        "\n",
        "Calculating the attention weights is done with another feed-forward\n",
        "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
        "Because there are sentences of all sizes in the training data, to\n",
        "actually create and train this layer we have to choose a maximum\n",
        "sentence length (input length, for encoder outputs) that it can apply\n",
        "to. Sentences of the maximum length will use all the attention weights,\n",
        "while shorter sentences will only use the first few.\n",
        "\n",
        "![image](https://pytorch.org/tutorials/_images/attention-decoder-network.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTgpqalYGaOR"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xa7siQKGqQE"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
        "  limitation by using a relative position approach. Read about \"local\n",
        "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
        "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
        "\n",
        "Training\n",
        "========\n",
        "\n",
        "Preparing Training Data\n",
        "-----------------------\n",
        "\n",
        "To train, for each pair we will need an input tensor (indexes of the\n",
        "words in the input sentence) and target tensor (indexes of the words in\n",
        "the target sentence). While creating these vectors we will append the\n",
        "EOS token to both sequences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mj3FhJBGoS_"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rtejHTjG5Ia"
      },
      "source": [
        "Training the Model\n",
        "------------------\n",
        "\n",
        "To train we run the input sentence through the encoder, and keep track\n",
        "of every output and the latest hidden state. Then the decoder is given\n",
        "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
        "encoder as its first hidden state.\n",
        "\n",
        "\"Teacher forcing\" is the concept of using the real target outputs as\n",
        "each next input, instead of using the decoder's guess as the next input.\n",
        "Using teacher forcing causes it to converge faster but [when the trained network is exploited, it may exhibit instability](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
        "\n",
        "You can observe outputs of teacher-forced networks that read with\n",
        "coherent grammar but wander far from the correct translation -\n",
        "intuitively it has learned to represent the output grammar and can \"pick\n",
        "up\" the meaning once the teacher tells it the first few words, but it\n",
        "has not properly learned how to create the sentence from the translation\n",
        "in the first place.\n",
        "\n",
        "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
        "choose to use teacher forcing or not with a simple if statement. Turn\n",
        "``teacher_forcing_ratio`` up to use more of it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWVqaIu-Gt3b"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A3z6eQtG3rv"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po1iCyBTHHIG"
      },
      "source": [
        "The whole training process looks like this:\n",
        "\n",
        "-  Start a timer\n",
        "-  Initialize optimizers and criterion\n",
        "-  Create set of training pairs\n",
        "-  Start empty losses array for plotting\n",
        "\n",
        "Then we call ``train`` many times and occasionally print the progress (%\n",
        "of examples, time so far, estimated time) and average loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gf1aSD1HFx_"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    # showPlot(plot_losses)\n",
        "    return plot_losses"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxLPtvy-HJv8"
      },
      "source": [
        "Plotting results\n",
        "----------------\n",
        "\n",
        "Plotting is done with matplotlib, using the array of loss values\n",
        "``plot_losses`` saved while training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kErPEK3PHIjD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.ylabel('Training Loss')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BWg0QVLHMnS"
      },
      "source": [
        "Evaluation\n",
        "==========\n",
        "\n",
        "Evaluation is mostly the same as training, but there are no targets so\n",
        "we simply feed the decoder's predictions back to itself for each step.\n",
        "Every time it predicts a word we add it to the output string, and if it\n",
        "predicts the EOS token we stop there. We also store the decoder's\n",
        "attention outputs for display later.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbjgrd4yHLMS"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEDyINR3HP8X"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the\n",
        "input, target, and output to make some subjective quality judgements:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41NOzzmRHOfs"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I3YLTtFHSkq"
      },
      "source": [
        "Training and Evaluating\n",
        "=======================\n",
        "\n",
        "With all these helper functions in place (it looks like extra work, but\n",
        "it makes it easier to run multiple experiments) we can actually\n",
        "initialize a network and start training.\n",
        "\n",
        "Remember that the input sentences were heavily filtered. For this small\n",
        "dataset we can use relatively small networks of 256 hidden nodes and a\n",
        "single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
        "reasonable results.\n",
        "\n",
        ".. Note::\n",
        "   If you run this notebook you can train, interrupt the kernel,\n",
        "   evaluate, and continue training later. Comment out the lines where the\n",
        "   encoder and decoder are initialized and run ``trainIters`` again.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSvZ-jJUUT0e",
        "outputId": "6cf0d653-de08-40e5-e7ed-7de476854b98"
      },
      "source": [
        "hidden_size = 300 #256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, weights_matrix).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "plot_losses = trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6m 27s (- 90m 22s) (5000 6%) 3.3636\n",
            "12m 52s (- 83m 42s) (10000 13%) 2.7571\n",
            "19m 19s (- 77m 17s) (15000 20%) 2.3692\n",
            "25m 46s (- 70m 51s) (20000 26%) 2.1001\n",
            "32m 12s (- 64m 24s) (25000 33%) 1.8624\n",
            "38m 39s (- 57m 59s) (30000 40%) 1.6947\n",
            "45m 7s (- 51m 34s) (35000 46%) 1.5429\n",
            "51m 33s (- 45m 6s) (40000 53%) 1.4161\n",
            "58m 0s (- 38m 40s) (45000 60%) 1.2803\n",
            "64m 24s (- 32m 12s) (50000 66%) 1.1457\n",
            "70m 52s (- 25m 46s) (55000 73%) 1.0729\n",
            "77m 18s (- 19m 19s) (60000 80%) 0.9919\n",
            "83m 46s (- 12m 53s) (65000 86%) 0.9408\n",
            "90m 13s (- 6m 26s) (70000 93%) 0.8829\n",
            "96m 40s (- 0m 0s) (75000 100%) 0.8556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbdPr0R_rt1d"
      },
      "source": [
        "pickle.dump(plot_losses, open(f'./plot_losses.pkl', 'wb'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Izb6m4n_vwk-",
        "outputId": "fc5f03e8-2541-40ca-ac81-a045fe1b57fb"
      },
      "source": [
        "showPlot(plot_losses)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_rlcrR1Iqld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3e6547-e2ad-4a52-d3c0-ea544e37b148"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> she is being blackmailed by him .\n",
            "= il exerce sur elle du chantage .\n",
            "< elle va beaucoup lui lui . <EOS>\n",
            "\n",
            "> you re very religious aren t you ?\n",
            "= vous etes tres religieuses n est ce pas ?\n",
            "< vous etes tres religieux n est ce pas ? <EOS>\n",
            "\n",
            "> he is on the team .\n",
            "= il fait partie de l equipe .\n",
            "< il est partie de la equipe . <EOS>\n",
            "\n",
            "> you re the leader .\n",
            "= c est vous la chef .\n",
            "< vous etes la chef chef . <EOS>\n",
            "\n",
            "> you are too young to travel alone .\n",
            "= vous etes trop jeunes pour voyager seuls .\n",
            "< vous etes trop jeune pour voyager seul . <EOS>\n",
            "\n",
            "> you aren t supposed to swim here .\n",
            "= tu n es pas cense nager ici .\n",
            "< vous n etes pas censees nager ici . <EOS>\n",
            "\n",
            "> he s no saint .\n",
            "= il n est pas un saint .\n",
            "< ce n est pas un saint . <EOS>\n",
            "\n",
            "> you re a woman now .\n",
            "= vous etes desormais une femme .\n",
            "< vous etes une femme maintenant . <EOS>\n",
            "\n",
            "> we re surprised .\n",
            "= nous sommes surprises .\n",
            "< nous sommes surpris . <EOS>\n",
            "\n",
            "> we re open tomorrow .\n",
            "= nous sommes ouverts demain .\n",
            "< nous sommes ouverts demain . <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4J1zvrwInJk"
      },
      "source": [
        "Visualizing Attention\n",
        "---------------------\n",
        "\n",
        "A useful property of the attention mechanism is its highly interpretable\n",
        "outputs. Because it is used to weight specific encoder outputs of the\n",
        "input sequence, we can imagine looking where the network is focused most\n",
        "at each time step.\n",
        "\n",
        "You could simply run ``plt.matshow(attentions)`` to see attention output\n",
        "displayed as a matrix, with the columns being input steps and rows being\n",
        "output steps:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "1t-jIrj1HVL9",
        "outputId": "704b7bf6-f06e-4528-c828-f213b7343f4b"
      },
      "source": [
        "%matplotlib inline\n",
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7fb819dc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5zYmdIDIvbR"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes\n",
        "and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6iRp2UgrIxPQ",
        "outputId": "0fb34969-dd90-4d97-d56f-0e8b8f2d51a5"
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"he is painting a picture .\")\n",
        "\n",
        "evaluateAndShowAttention(\"why not try that delicious wine ?\")\n",
        "\n",
        "evaluateAndShowAttention(\"she is not a poet but a novelist .\")\n",
        "\n",
        "evaluateAndShowAttention(\"you re too skinny .\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = he is painting a picture .\n",
            "output = il est en train de faire un roman . <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "input = why not try that delicious wine ?\n",
            "output = ce n est pas pas vrai ce pas ? <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "input = she is not a poet but a novelist .\n",
            "output = elle n est pas poete mais romanciere . <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEcCAYAAAAx7YQgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfgklEQVR4nO3debhcVZ3u8e+biAwGEYntwBTEgAIKQsSJVlS0o4Lc54ICgoKCaWe9ioqKXBvbbtHb+IgyBYmA0qKCQ1pRaGxAAcUkBhISiaZBJVy9GpVBBCQ57/1j7wPF8ZyqOjlVtfeuvB+e/bCHVWuvU5Xzq3XWXoNsExERzTSt6gJERMSGSxCPiGiwBPGIiAZLEI+IaLAE8YiIBksQj4hosATxiIgGSxCPGHKSNu3mXDRTgnjE8PtRl+eigR5RdQEioj8kPQHYFthc0jMBlZceDWxRWcGipxLEI4bXPwDHANsB/8ZDQfxu4EMVlSl6TJk7JWK4STrE9iVVl2MqJAn4BvBB2z+rujx1kjbxiOG3naRHq/B5ST+V9LKqCzVJLwOeBRxXdUHqJkE8Yvi90fZdFIFwG+B1wCeqLdKkHUsRwA+SlGbgFgniEcNvtC38FcAFtle0nKs9STOB3W1/F7gC+B8VF6lWEsQjht8SSZdTBPHLJG0JjFRcpsl4HfDlcv8LpEnlYfJgM2LISZoG7AXcYvsOSdsA29peVnHRuiJpOTDX9u3l8Y3AgbZvq7Zk9ZC2pYghJemptm+mCOAATy46eTSHpMcAnxsN4KXjgZlAgjipiUcMLUnn2H6TpCvHuWzbLx54oaLnEsQjopYkvQm4yvYvyn7iC4BDgF8CR9teWmX56iLNKRFDStL/bHfd9tcHVZYN9C7gvHL/COAZwE7AM4HTgL+vplj1kiAeMbwOanPNQN2D+DrbD5T7B1J0j/wDcIWkT1ZYrlpJEI8YUrbfUHUZpmhE0hOBPwEvAT7ecm3zaopUP+knHjHkJD1e0rmSvlse7ybp2KrL1YWTgMUUbeALy0FKSHohcEuF5aqVPNiMRpO0qe37O53bmJXB+wvAh23vWQ5bX2r76RUXraOyrFva/lPLuUdRxK4/V1ey+khNPJouCx50NtP2VylHadpeB6yvtkhdeyzwbkkXl9s/ATMSwB+SNvFopCx4MCn3lKM0DSDpOcCd1RapM0nPB/6doofKBeXpfYDrJR1p+9qqylYnaU6JRpJ0NMWCB3Mo2k1H3QWc34DucwMjaR+KLnl7ADcBjwMOrfuwe0k/Bt4ytj+4pL2As20/u5qS1UuCeDTaMCx4MAhl2/KuFH+xrGrpuldbklba3m2y1zY2aROfIkmbS9q16nJsxK5taM+LgZG0DHg/cJ/tm5oQwEuStPU4Jx9LYteD8kZMgaSDgBuA75XHe0laWG2pJkfSpt2cq7EvAJcBTyqPfw68u1eZl+2yHc/V3EHAOuCrkhZJOl7SDlUXqgufBi6X9EJJW5bb/sB3y2tBmlOmRNIS4MUU8zs8szy3vAldt0ZJ+qntvTudqytJi2w/S9LSls/gBtt7dXptl/k3+v0ZS9Js4CPAkbanV12eTiQdSPFXxO4UD2ZXAp+y/R+VFqxG0jtlah6wfeeY6T0b8a04RL07+tLzQtJzgecBj5P0npZLjwZqH/zGkrQjcFi5racIjLVn+9vAt6suR50liE/NCkmvBaaXNZx3AtdVXKZu/QNF747tgFNbzt8NfKiKAm2g9wALgZ0lXUvZ86IH+T4SmEHxO7Jly/m7epT/wEi6HtgE+BrwatuNGO0o6au2X1Pun2L7Ay3XLrfdtMWe+yLNKVMgaQvgwxQL0IqibfZjtu+rtGCTMAy9O/rZ80LSjrZ/1av8qiBpV9urqi7HZI1pIntYE1brtY1dgvhGrlw55STgBeWpq4GTbdd+MAiApE2At/BQ+a+i6EPck0BeLqjwN78kTVpQQdJWwP+mYZ9xa+AeJ4g39rlEr6U5ZQok7UKxVNQsWt7LJv2CA+dSDAB5TXn8OooeH23noq6RMymaCs4oj19XnuvVYrrHt+xvRrEowboe5T0oC2jmZ7xF+bxmGg9/diMyi+GDUhOfgnLB1rOAJbTMRWF7SWWFmqTxenL0sndHv0m60faenc71+J4/sb1vv/LvtaZ+xhMsK/cg2y8aVFnqLDXxqVln+8yqCzFF90raz/Y18GAf6HsrLtNkrJe0s+3/BpD0ZHo4uVM5sGTUNIph/lv1Kv8BaeRnnCDdnQTxDdDyi/0fkt4KfAN4cOpT23/s4b2eD9xg+x5JRwF7A5/p4cO2twDnl+2mUEzAf3SP8h6E9wFXShrtcTEL6OViCEt4qE18HcXc1k0bEdrYz1jS5sAutm9sObcDsN727dWVrD7SnLIBJN1K8Yvd2kH8wTfS9pN7eK9lwJ4U6wueB3weeI3tF/Yo/00pusztDDyGoo+1bZ/ci/zLe2wNzKZoU4biBj/oUd6bAe+lWPnlDmAR8Ole9RAqg8hbgf0oPuMfAmf2sgdSP9+fMv++f8b9Uj64vhl4hu17ynOXAx+yvbjtizcSqYlvANs7AUh6DfA923dJ+ghFLfljPb7dOtuWdDDwOdvn9nhukG9RBL+fAj2v2Ug6jmLB2+0opih4DsV83716+HsBRd/t0ff9tcAXgVf3KP/zy/xP60f+A3h/oM+fcT/ZfkDSNygeyn6hrIU/LgG8he1sG7gBy8r/7wdcCbwSuL7H97ga+CDFnCBPoGiXXd7D/G/q83u0nKKGeUN5/FTg6z3Mf2U352qcf1/fn0F8xv3eyvfkB+X+icA7qy5TnbZMgDU1ow/QXgmcY/s7FCP9eukwivb2Y23/lqLG9qke5n+dpH7O9XKfy6YHFcum3UwxMKdXfloOtae8x7N5+Pzidc+/3+8P9P8z7qvyPVHZpfdwir+EopTmlKm5XdLZwEuBU8q2x55+MZaB+9SW41/z0ConvbAfcEzZzn8/RTu/bT+jR/mvKQcUfRP4T0l/Ano5AnIfiiD16/J4B2CVpOVM4ecYfT1FH/TR/A3sSNFG2yv9fn+g/5/x35D0hPLfbq+cS/E8aLlb1tuMPNicknLY/VyKf1i/kPRE4Om2L+9B3tfY3k/S3Tx8xODoL+Cjp3qP8j47jnfefRhqrmKV8q0oniP8tUd5jlv+URv6c/Qr3w737Pn7U+Y7sM+45Z7fsf3KHua3BfAb4BDbV/Qq32GQIB4R0WBpE4+IaLAE8YiIAZG0QNLvJN00wXVJOk3SaknLJHWc5CtBvIckzUv+w5v/IO6R/KvNfwDOo3iONpGXUwz8mg3Mo5jMra0E8d7q9z+w5F9t/oO4R/KvNv++cjESt920HAcDF7jwY+AxZYeJCSWIR0TUx7bAbS3Ha8pzE0o/8TZmzpzpWbNmdZ1+hx12YM6cOV1391myZPIz1krqa3ei5F/9PZJ/b/O3rc6pJjZ37lyvXbu2q7RLlixZAbTOqzPf9vyp3L+TBPE2Zs2axeLF/ZuiQZrSv62IGIC1a9d2HQck3Wd7zhRudzuwfcvxdnSY7ybNKRERHUxinpepWgi8vuyl8hzgTtu/afeC1MQjItowsH5kpCd5SfoysD8wU9IairVPNwGwfRZwKfAKYDXwF7qYGz9BPCKiLeO/XSt7w3Kyj+hw3cDbJpNngnhERDuGkRrPTpIgHhHRQZ3nmEoQj4how8BIgnhERHPVuSY+dF0MJf1S0sxy/89Vlycims0260dGutqqkJp4REQHqYn3iaSjJP1E0g2SzpY0vU3a90laVE7v+E+DLGdENJu7/K8KjQ3ikp5GsYjw823vRbFo8ZETpH0ZxdSO+wJ7AftIesEEaedJWixp8e9///v+FD4iGqN4sNndVoUmN6e8hGKR3EXlHCSbA7+bIO3Lym1peTyDIqj/YGzCcrKa+cCkJrOKiOFV5+aUJgdxAefb/uDDTkrHTJD2X22fPYiCRcQQKR9s1lVjm1OA7wOHSvo7AEmPbbNC+WXAGyXNKNNuO/q6iIh2zEAnwJq0xtbEba+UdCJwuaRpwANMMOeA7cvLNvQflU0vfwaOYuLml4iIB2WwT5/Y/grwlTGnZ7Vcn9Gy/xngM4MpWUQMk7SJR0Q0VnXdB7uRIB4R0YYzi2FERLON1Lh3SoJ4REQbmcUwIqLh8mAzIqKp7NTEm2rJkiWU/cpjAv2uoeT9jzpITTwioqEMrE8Qj4hortTEIyIaLEE8IqKhnAebERHNlpp4RESDJYhHRDRU0Tslw+4jIhorE2BFRDRVhav2dCNBPCKijdHl2epqownikmYB3wWuAZ4H3A4cbPveCosVEQ1Q5y6GTV4oeUPMBk63vTtwB3BIxeWJiAbIQsn1cavtG8r9JbSsxzlK0jxg3iALFRH1ZZv1WRSiNu5v2V8PbD42ge35wHwASfX9GyoiBiZrbEZENFiduxhubG3iERGTMto7pVdt4pLmSlolabWkE8a5voOkKyUtlbRM0iva5bfR1MRt/xLYo+X4/1RXmohokl49tJQ0HTgdeCmwBlgkaaHtlS3JTgS+avtMSbsBlzLO87tRG00Qj4jYIL19sLkvsNr2LQCSLgIOBlqDuIFHl/tbAf+3XYYJ4hERbfR4sM+2wG0tx2uAZ49J81HgcknvAB4FHNAuw7SJR0R0MFLOKd5pA2ZKWtyybUh35SOA82xvB7wC+KKkCWN1auIRER1MoovhWttz2ly/Hdi+5Xi78lyrY4G5ALZ/JGkzYCbwu/EyTE08IqIDu7utC4uA2ZJ2kvRI4HBg4Zg0vwZeAiDpacBmwO8nyjA18YiINkzv5k6xvU7S24HLgOnAAtsrJJ0MLLa9EHgvcI6k/1Xe/hi3aZRPEI8pkdTX/Ps9H0W/yx9DoMfD7m1fStFtsPXcSS37K4Hnd5tfgnhERBuZijYiouESxCMiGqzO84kniEdEtOXMYhgR0VST6D5YiQTxiIgOsihERERD9bKfeD8kiEdEdFDn3ikb3bB7ScdIelLV5YiIhuhyQYiqAv1GF8SBY4AE8YjoXg8nT+m1oWlOkXQU8E7gkcD1wFuBc4E5FM1aCyjm8Z0DXCjpXuC5tu+tpsQR0RQj6+vbnDIUQbyc6esw4Pm2H5B0BsUSR9va3qNM8xjbd5STzxxve3GFRY6Ihigq2Qni/fYSYB+K9eoANge+BzxZ0meB7wCXd5NROYn7hkzkHhFDqs5BfFjaxAWcb3uvctvV9ruAPYGrgDcDn+8mI9vzbc/pMLF7RGw08mBzEL4PHCrp7wAkPVbSjsA025dQNK3sXaa9G9iymmJGRBN5xF1tVRiK5hTbKyWdSLG46DTgAeA9wDda1qb7YPn/84Cz8mAzIrqRNvEBsf0V4CtjTu89TrpLgEsGUqiIGArOsPuIiOaqcUU8QTwioi1X197djQTxiIgO0iYeEdFQWWMzIqLhEsQjIprKxuvTOyUiorFSE4+IaLAax/AE8YiIdvJgMyKiyTLsPiKiycxIHmxGRDRXauIREQ2VWQwjIpouQTwiorlc3ybxBPGIiE7SnBIR0VQ2IzVeFKLRa2xKmiXpZkkXSvqZpIslbSHpJEmLJN0kab4klenfKWmlpGWSLqq6/BFRf6ODfXq1ULKkuZJWSVot6YQJ0rymjFUrJP17u/waHcRLuwJn2H4acBfwVuBztp9lew9gc+DAMu0JwDNtPwN4cyWljYhmce8WSpY0HTgdeDmwG3CEpN3GpJlNsSbw823vDry7XZ7DEMRvs31tuf8lYD/gRZKul7QceDGwe3l9GXChpKOAdeNlJmmepMWSFve74BHREEU/w85bZ/sCq23fYvuvwEXAwWPSvAk43fafilv7d+0yHIYgPvadM3AGcKjtpwPnAJuV115J8S24N7BI0t88E7A93/Yc23P6WOaIaIzumlK6bE7ZFrit5XhNea7VLsAukq6V9GNJc9tlOAxBfAdJzy33XwtcU+6vlTQDOBRA0jRge9tXAh8AtgJmDLqwEdE8IyPuagNmjv4lX27zNuB2jwBmA/sDRwDnSHpMu8RNtwp4m6QFwErgTGBr4Cbgt8CiMt104EuStgIEnGb7jgrKGxEN4rJNvEtrO/wVfzuwfcvxduW5VmuA620/ANwq6ecUQX0R4xiGIL7O9lFjzp1YbmPtN4DyRMSQ6WE/8UXAbEk7UQTvwylaEFp9k6IG/gVJMymaV26ZKMNhCOIREX3VqyBue52ktwOXUbQOLLC9QtLJwGLbC8trL5O0ElgPvM/2HybKs9FB3PYvgT2qLkdEDLPu+4B3lZt9KXDpmHMntewbeE+5ddToIB4R0XeZxTAiorkMeH2CeEREY6UmHhHRVJOYF6UKCeIRER1Mop/4wCWIR62VE1D2Tb9rWP0ufwxGauIREQ01OhVtXSWIR0S0Y+MaLwqRIB4R0UHW2IyIaLA0p0RENFVGbEZENFcebEZENJoZWV/fRvFhWNlnXJKOkfSkqssREQ3n3q5232tDG8SBY4AE8YiYut4tlNxztQvikmZJulnShZJ+JuliSVtIeomkpZKWS1ogadMy/T6Srpa0RNJlkp4o6VBgDsXK9jdI2ny8dNX+pBHRFDWO4fUL4qVdgTNsPw24i2Jy9POAw8oV7B8BvEXSJsBnKVa23wdYAHzc9sXAYuBI23sB68ZLN+CfKSIaaPTBZl2bU+r6YPM229eW+18CPgLcavvn5bnzgbcBV1Cs7POf5RwV04HfjJPfrl2mo1ydekNWqI6IYTS5hZIHrq5BfOw7dgewzTjpBKyw/dwO+XWbDtvzgfkAkur7yUXEgJiRGg+7r2tzyg6SRgPuaymaRmZJekp57nXA1cAq4HGjaSVtImn3Ms3dwJblfrt0ERFt1bk5pa5BfBXwNkk/A7YGPg28AfiapOXACHCW7b8ChwKnSLoRuAF4XpnHecBZkm6gaD6ZKF1ERHs1frJZ1+aUdbaPGnPu+8Azxya0fQPwgnHOXwJc0nJq3HQREe04beIREc1W41H39Qvitn9J0ZMkIqIGssZmRERzmVr3TkkQj4how6RNPCKi0dKcEhHRWBVOjNKFBPGIiHaysk9ERLONrE8Qj4hopCzPFhHRZGlOiYhosgz2iYhotATxiIgGq/Ngn7pORRsRUQujsxh2s3VD0lxJqyStlnRCm3SHSLKkOe3ySxCPiOigV4tCSJoOnA68HNgNOELSbuOk2xJ4F3B9pzyHPohLmiPptKrLERFN1V0A77LdfF9gte1bykVtLgIOHifdx4BTgPs6ZTj0Qdz2YtvvrLocEdFQvW1O2Ra4reV4TXnuQZL2Bra3/Z1uMmxEEJc0S9LNks6T9HNJF0o6QNK1kn4had9y+5GkpZKuk7Rr+dr9JX273H+hpBvKbWn5J0tERFuTqInPlLS4ZZs3mftImgacCry329c0qXfKU4BXA28EFlEsoLwf8CrgQ8Drgb+3vU7SAcC/AIeMyeN44G22r5U0gy7+VImIjdskR2yutd3uQeTtwPYtx9uV50ZtSbEozlWSAJ4ALJT0KtuLx8uwSUH8VtvLASStAL5v2+XCybOArYDzJc2meN83GSePa4FTJV0IfN32mrEJym/OSX17RsQwM+7dohCLgNmSdqII3odTVEiLO9l3AjNHjyVdBRw/UQCHhjSnlO5v2R9pOR6h+DL6GHCl7T2Ag4DNxmZg+xPAccDmwLWSnjpOmvm253T4No2IjYXBI91tHbOy1wFvBy4DfgZ81fYKSSdLetWGFK9JNfFOtuKhP0uOGS+BpJ3L2vxySc8CngrcPJjiRURT9XLEpu1LgUvHnDtpgrT7d8qvSTXxTj4J/KukpUz85fRuSTdJWgY8AHx3YKWLiMbqYRfDnmtETdz2Lyka+0ePj5ng2i4tLzuxvH4VcFW5/45+ljMihk+moo2IaDKbkfVZ7T4iorlSE4+IaC6TIB4R0UjOyj4REU1m3E0n8IokiEdEdJCaeEREg430bth9zyWIx0atnGSob/pdg+t3+WN0oE+CeEREc6U5JSKiudLFMCKiwfJgMyKisczIyPqqCzGhBPGIiDYy2CciouESxCMiGixBvMckvRn4i+0Lqi5LRAw7D08XQxUjC+SKe77bPmsy6SU9olzbLiJi0kx9B/t0XJ5N0ixJqyRdANwEnFsucbZc0mFlmv0lXS3pW5JukfQJSUdK+kmZbucy3UGSrpe0VNIVkh5fnv+opAWSripf/86W+79e0jJJN0r6Ykv648v9nSV9T9ISST8cXfxY0nmSzpJ0PfDJidJFRLRjF8Puu9mq0G1NfDZwNLAt8GZgT2AmsEjSD8o0ewJPA/4I3AJ83va+kt4FvAN4N3AN8BzblnQc8H7gveXrnwq8CNgSWCXpTIrl1k4Enmd7raTHjlO2+cCbbf9C0rOBM4AXl9e2K1+7XtL326SLiJhAdetndqPbIP4r2z+W9Gngy7bXA/9P0tXAs4C7gEW2fwMg6b+By8vXLqcIzlAE1a9IeiLwSODWlnt8x/b9wP2Sfgc8niLIfs32WgDbf2wtlKQZwPOAr7XMIbFpS5KvlQG8U7rWPOcB87p8XyJiIzAMc6fc00Wa+1v2R1qOR1ru81ngVNsLJe0PfHSC16/vsmzTgDts7zXB9Xu6TPcg2/MpavdIqu/Xb0QMTJ1r4h3bxMf4IXCYpOmSHge8APjJJF6/FXB7uX90F+n/C3i1pG0Axjan2L4LuFXSq8vrkrTn2Ey6TRcRMZ5iJsPOWxUmG8S/ASwDbqQIsO+3/dtJvP6jFE0aS4C1nRLbXgF8HLha0o3AqeMkOxI4try+Ajh4guy6TRcR8RC7+60CqvOfCVVLc0pMVeYTr57tKb1JM2Zs7T333L+rtNdd980ltudM5X6T1cjBPhERgzMcvVMiIjZaCeIREQ2WIB4R0VDFM8vm9xOPiNhIGWe1+4iI5soamxERDZY28YiIxnKt28QnO2IzImKjMrrGZq+G3UuaW07vvVrSCeNcf4+kleUU3N+XtGO7/BLEIyI66FUQlzQdOB14ObAbcISk3cYkWwrMsf0M4GLgk+3yTBCPiOigh4tC7Austn2L7b8CFzFmHifbV9r+S3n4Y4opvCeUIB4R0ZbBI91tnW0L3NZyvKY8N5Fjge+2yzAPNiMiOphEF8OZkha3HM8v1yiYNElHAXOAF7ZLlyAeEdHG6IPNLq3tMIvh7cD2Lcfb8dAaCw+SdADwYeCF5YpnE0oQj4jooIf9xBcBsyXtRBG8Dwde25pA0jOBs4G5tn/XKcME8YiItnrXT9z2OklvBy4DpgMLbK+QdDKw2PZC4FPADB5aE/jXtl81UZ4J4hERHXTZ86Qrti8FLh1z7qSW/QMmk1+CeEREG5NsEx+4BPGIiLaqWz+zGwniEREdmPrOnZIgPoakecC8qssREfWR5pQGKTvmz4esdh8RAO7pg81eSxCPiGij7suzbbRzp0i6VNKTqi5HRNRfL6ei7bWNtiZu+xVVlyEimiFt4hERjZUuhhERjZaFkiMiGsqGkZH1VRdjQgniERFtVffQshsJ4hERHSSIR0Q0WIJ4RESD1XmwT4J4RB+Vk/r3zSBqiP3+GWrP6WIYEdFYBkZSE4+IaK40p0RENFa6GEZENFqCeEREQ2WNzYiIRjPOsPuIiOaq8wRYtVsUQtJVklZJuqHcLm65Nk/SzeX2E0n7tVw7UNJSSTdKWinpH6v5CSJi2GRRiA4kPRLYxPY95akjbS8ek+ZA4B+B/WyvlbQ38E1J+wJ/oFgXc1/bayRtCswqX7e17T8N6meJiOFT5zbxSmvikp4m6d+AVcAuHZJ/AHif7bUAtn8KnA+8DdiS4gvpD+W1+22vKl93mKSbJL1X0uP68XNExPAqatkjXW1VGHgQl/QoSW+QdA1wDrASeIbtpS3JLmxpTvlUeW53YMmY7BYDu9v+I7AQ+JWkL0s6UtI0ANtnAS8HtgB+IOliSXNHr0dEdJLmlIf7DbAMOM72zROk+ZvmlE5sHyfp6cABwPHAS4Fjymu3AR+T9M8UAX0BxRfAq8bmI2keMG8y946I4TYyUt8Rm1XURg8Fbge+LukkSTt2+bqVwD5jzu0DrBg9sL3c9qcpAvghrQnLtvMzgNOArwIfHO8mtufbnmN7TpfliohhNzoJVqetAgMP4rYvt30Y8PfAncC3JF0haVaHl34SOEXSNgCS9qKoaZ8haYak/VvS7gX8qkz3MknLgH8GrgR2s/1u2yuIiOjImJGutipU1jvF9h+AzwCfKWvJrb3pL5R0b7m/1vYBthdK2ha4TpKBu4GjbP9G0pbA+yWdDdwL3EPZlELxsPMg278awI8VEUOm7iM2VefCVa38soiorcwn3pntKf0A06ZN96abbt5V2vvuu2fJoJtia9FPPCKizupc2U0Qj4hoy4xk7pSIiGaqe5t4BrxERHTSwy6G5WDDVZJWSzphnOubSvpKef36Tj33EsQjItpy1/91Imk6cDrFoMPdgCMk7TYm2bHAn2w/Bfg0cEq7PBPEIyI66OHcKfsCq23fYvuvwEXAwWPSHEwxLxTAxcBL1KaLUNrEIyI66OGw+22B21qO1wDPniiN7XWS7gS2AdaOl2GCeHtrKUd+dmkmE7zRPZL8q81/EPeYVP4b0Ie7VuUfQP7dTuvRzmXlfbuxmaTWeZ/m257fgzJMKEG8DduTmrpW0uJ+dvRP/tXmP4h7JP9q8x+P7bk9zO52YPuW4+3Kc+OlWSPpEcBWlNNsjydt4hERg7MImC1pp3IxnMMpptFutRA4utw/FPgvt+njmJp4RMSAlG3cb6doopkOLLC9QtLJwGLbC4FzgS9KWg38kSLQTyhBvLf62vaV/CvPfxD3SP7V5t93ti8FLh1z7qSW/fuAV3ebXybAiohosLSJR0Q0WIJ4RESDJYhHRDRYgnhERIMliEdENFiCeEREgyWIR0Q02P8Hc2KQ15JCtKgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "input = you re too skinny .\n",
            "output = vous etes trop maigrichonne . <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}